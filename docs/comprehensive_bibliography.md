# Comprehensive Bibliography
## The Foundations of Large Language Models, 1906 - 2025

---

## **Part 0 – Probabilistic & Mathematical Foundations (1906–1943)**

1. **Markov (1906-1913)** — Markov Chains and Stochastic Processes
   - Historical resource: https://medium.com/@lahsaini/the-100-year-old-math-feud-that-powers-google-and-chatgpt-60284acc27a8
   - *Need to find primary source or authoritative historical paper*

2. **McCulloch & Pitts (1943)** — [A Logical Calculus of the Ideas Immanent in Nervous Activity](https://www.cs.cmu.edu/~epxing/Class/10715/reading/McCulloch.and.Pitts.pdf)

---

## **Part I – Neural Beginnings & Learning Mechanisms (1943–1990)**

3. **Rosenblatt (1958)** — [The Perceptron](https://www.cse.chalmers.se/~coquand/AIP/perceptron.pdf)

4. **Minsky & Papert (1969)** — [Perceptrons](https://web.media.mit.edu/~minsky/papers/Perceptrons1969.pdf)
   - *May be partial; need to verify accessibility*

5. **Bellman (1957)** — Dynamic Programming *(NEW)*
   - *Need to find: "Dynamic Programming" - Princeton University Press*
   - Alternative: Key papers on Bellman equations and dynamic programming

6. **Hopfield (1982)** — [Neural Networks and Physical Systems with Emergent Collective Computational Abilities](https://www.pnas.org/doi/pdf/10.1073/pnas.79.8.2554)

7. **Rumelhart, Hinton & Williams (1986)** — [Learning Representations by Back-Propagating Errors](https://www.cs.toronto.edu/~fritz/absps/naturebp.pdf)

8. **Watkins (1989/1992)** — Q-Learning *(NEW)*
   - Original: Watkins, C.J.C.H. (1989). "Learning from delayed rewards" - PhD thesis
   - Paper: https://link.springer.com/article/10.1007/BF00992698 (1992)
   - *Need to find accessible PDF*

---

## **Part II – Sequence Models & Word Embeddings (1990–2013)**

9. **Elman (1990)** — [Finding Structure in Time](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)

10. **Hochreiter & Schmidhuber (1997)** — [Long Short-Term Memory](https://www.bioinf.jku.at/publications/older/2604.pdf)

11. **Bengio et al. (2003)** — [A Neural Probabilistic Language Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)

12. **Mikolov et al. (2010)** — [Recurrent Neural Network Based Language Model](https://www.isca-speech.org/archive/archive_papers/interspeech_2010/i10_1045.pdf)

13. **Mikolov et al. (2013)** — [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)

14. **Pennington et al. (2014)** — [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)

---

## **Part III – Attention and Sequence-to-Sequence (2014–2016)**

15. **Sutskever et al. (2014)** — [Sequence to Sequence Learning with Neural Networks](https://papers.nips.cc/paper_files/paper/2014/file/a14ac55a4f27472c5d894ec1c3c743d2-Paper.pdf)

16. **Mnih et al. (2015)** — Human-level control through deep reinforcement learning (DQN) *(NEW)*
    - https://www.nature.com/articles/nature14236
    - https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf

17. **Bahdanau et al. (2014)** — [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)

18. **Sennrich et al. (2015)** — [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/pdf/1508.07909.pdf)

19. **Mnih et al. (2016)** — Asynchronous Methods for Deep Reinforcement Learning (A3C) *(NEW)*
    - https://arxiv.org/pdf/1602.01783.pdf

---

## **Part IV – The Transformer Era and Pretraining (2017–2019)**

20. **Vaswani et al. (2017)** — [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)

21. **Schulman et al. (2017)** — Proximal Policy Optimization Algorithms (PPO) *(NEW)*
    - https://arxiv.org/pdf/1707.06347.pdf

22. **Christiano et al. (2017)** — Deep reinforcement learning from human preferences (RLHF) *(NEW)*
    - https://arxiv.org/pdf/1706.03741.pdf

23. **Espeholt et al. (2018)** — IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures *(NEW)*
    - https://arxiv.org/pdf/1802.01561.pdf

24. **Peters et al. (2018)** — [Deep Contextualized Word Representations (ELMo)](https://arxiv.org/pdf/1802.05365.pdf)

25. **Howard & Ruder (2018)** — [Universal Language Model Fine-Tuning for Text Classification (ULMFiT)](https://arxiv.org/pdf/1801.06146.pdf)

26. **Devlin et al. (2018)** — [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)

27. **Radford et al. (2018)** — [Improving Language Understanding by Generative Pre-Training (GPT-1)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

---

## **Part V – Emergence and Scale (2019–2020)**

28. **Radford et al. (2019)** — [Language Models are Unsupervised Multitask Learners (GPT-2)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

29. **Brown et al. (2020)** — [Language Models are Few-Shot Learners (GPT-3)](https://arxiv.org/pdf/2005.14165.pdf)

30. **Kaplan et al. (2020)** — [Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361.pdf)

31. **Choromanski et al. (2020)** — [Rethinking Attention with Performers](https://arxiv.org/pdf/2009.14794.pdf)

32. **Lewis et al. (2020)** — [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf)

---

## **Part VI – Efficiency, Alignment, and Reasoning (2021–2022)**

33. **Hu et al. (2021)** — [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf)

34. **Su et al. (2021)** — [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/pdf/2104.09864.pdf)

35. **Press et al. (2021)** — [Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation (ALiBi)](https://arxiv.org/pdf/2108.12409.pdf)

36. **Borgeaud et al. (2021)** — [Improving language models by retrieving from trillions of tokens (RETRO)](https://arxiv.org/pdf/2112.04426.pdf)

37. **Fedus et al. (2022)** — [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/pdf/2101.03961.pdf)

38. **Dao et al. (2022)** — [FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness](https://arxiv.org/pdf/2205.14135.pdf)

39. **Ouyang et al. (2022)** — [Training language models to follow instructions with human feedback (InstructGPT)](https://arxiv.org/pdf/2203.02155.pdf)

40. **Bai et al. (2022)** — [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/pdf/2212.08073.pdf)

41. **Wei et al. (2022)** — [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903.pdf)

42. **Yao et al. (2022)** — [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629.pdf)

43. **Hoffmann et al. (2022)** — [Training Compute-Optimal Large Language Models (Chinchilla)](https://arxiv.org/pdf/2203.15556.pdf)

---

## **Part VII – Open Models & Advanced Alignment (2023–2024)**

44. **Touvron et al. (2023)** — [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf)

45. **Rafailov et al. (2023)** — Direct Preference Optimization: Your Language Model is Secretly a Reward Model (DPO) *(NEW)*
    - https://arxiv.org/pdf/2305.18290.pdf

46. **Lee et al. (2023)** — RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback *(NEW)*
    - https://arxiv.org/pdf/2309.00267.pdf

47. **Liu et al. (2023)** — Ring Attention with Blockwise Transformers for Near-Infinite Context *(NEW)*
    - https://arxiv.org/pdf/2310.01889.pdf

48. **Dettmers et al. (2023)** — [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/pdf/2305.14314.pdf)

49. **Munkhdalai et al. (2024)** — Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention *(NEW)*
    - https://arxiv.org/pdf/2404.07143.pdf

50. **Yuan et al. (2024)** — Self-Rewarding Language Models *(NEW)*
    - https://arxiv.org/pdf/2401.10020.pdf

51. **Touvron et al. (2024)** — The Llama 3 Herd of Models *(NEW)*
    - https://arxiv.org/pdf/2407.21783.pdf

52. **Shao et al. (2024)** — DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models *(NEW)*
    - https://arxiv.org/pdf/2402.03300.pdf

53. **Zhu et al. (2024)** — DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model *(NEW)*
    - https://arxiv.org/pdf/2405.04434.pdf

54. **Mistral AI (2024)** — [Mixtral of Experts](https://arxiv.org/pdf/2401.04088.pdf)

55. **Snell et al. (2024)** — Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters *(NEW)*
    - https://arxiv.org/pdf/2408.03314.pdf

---

## **Appendix A – Emerging Research (2024-2025)**

56. **Wang et al. (2025)** — [Long-Input Fine-Tuning: A Better Way to Use Long Context](https://arxiv.org/pdf/2402.05352.pdf)

57. **Zhao et al. (2025)** — [RoPE Extrapolation Without Retraining](https://arxiv.org/pdf/2404.06691.pdf)

58. **Jiang et al. (2025)** — [InftyThink: Curriculum-Based Long-Form Reasoning](https://arxiv.org/pdf/2403.07513.pdf)

59. **Li et al. (2025)** — [Sparse MoE as Unified Competitive Learning](https://arxiv.org/pdf/2403.09674.pdf)

60. **Zhang et al. (2025)** — [Mixture of Grouped Experts](https://arxiv.org/pdf/2405.04122.pdf)

61. **Chen et al. (2025)** — [Private Steering for Alignment](https://arxiv.org/pdf/2401.06086.pdf)

62. **Li et al. (2025)** — [Reasoning-as-Logic-Units](https://arxiv.org/pdf/2402.02862.pdf)

63. **Kumar et al. (2025)** — LLM Post-Training: A Deep Dive into Reasoning Large Language Models *(Survey)* *(NEW)*
    - https://arxiv.org/pdf/2502.21321.pdf

64. **Xu et al. (2025)** — Large Language Diffusion Models (LLaDA) *(NEW - if groundbreaking)*
    - https://arxiv.org/pdf/2502.09992.pdf

---

## **Appendix B – System Reports & Production Breakthroughs (2023-2025)**

### **2023-2024 Production Systems:**

**OpenAI (2023)** — [GPT-4 Technical Report](https://arxiv.org/pdf/2303.08774.pdf)

**Anthropic (2024)** — [The Claude 3 Model Family: Opus, Sonnet, Haiku](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)

**DeepMind (2024)** — [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf)

**Qwen Team (2024)** — Qwen2.5 Technical Report *(NEW)*
- https://arxiv.org/pdf/2412.15115.pdf

**DeepSeek-AI (2024)** — DeepSeek-V3 Technical Report *(NEW)*
- https://arxiv.org/pdf/2412.19437.pdf
- *671B MoE with auxiliary-loss-free routing and Multi-Head Latent Attention*

### **2024-2025 Reasoning & Test-Time Compute Systems:**

**OpenAI (2024)** — o1 System Card *(NEW)*
- https://arxiv.org/pdf/2412.16720.pdf

**OpenAI (2025)** — Competitive Programming with Large Reasoning Models (o3) *(NEW)*
- https://arxiv.org/pdf/2502.06807.pdf

### **2024 Long-Context Systems:**

**Qwen Team (2025)** — Qwen2.5-1M Technical Report
- https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2.5-1M/Qwen2_5_1M_Technical_Report.pdf

---

## **Papers to Download (NEW):**

### **Priority 1 - Foundational RL & Alignment:**
1. Bellman (1957) - Dynamic Programming [*need to find accessible source*]
2. Watkins Q-Learning (1992) - https://link.springer.com/article/10.1007/BF00992698
3. Mnih et al. (2015) DQN - https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf
4. Mnih et al. (2016) A3C - https://arxiv.org/pdf/1602.01783.pdf
5. Schulman et al. (2017) PPO - https://arxiv.org/pdf/1707.06347.pdf
6. Christiano et al. (2017) RLHF - https://arxiv.org/pdf/1706.03741.pdf
7. Espeholt et al. (2018) IMPALA - https://arxiv.org/pdf/1802.01561.pdf

### **Priority 2 - AI Feedback & Modern Alignment:**
8. Rafailov et al. (2023) DPO - https://arxiv.org/pdf/2305.18290.pdf
9. Lee et al. (2023) RLAIF - https://arxiv.org/pdf/2309.00267.pdf
10. Yuan et al. (2024) Self-Rewarding - https://arxiv.org/pdf/2401.10020.pdf

### **Priority 3 - Architecture & Efficiency:**
11. Liu et al. (2023) Ring Attention - https://arxiv.org/pdf/2310.01889.pdf
12. Munkhdalai et al. (2024) Infini-attention - https://arxiv.org/pdf/2404.07143.pdf
13. Zhu et al. (2024) DeepSeek-V2 - https://arxiv.org/pdf/2405.04434.pdf
14. Touvron et al. (2024) Llama 3 - https://arxiv.org/pdf/2407.21783.pdf
15. Shao et al. (2024) DeepSeekMath - https://arxiv.org/pdf/2402.03300.pdf

### **Priority 4 - Test-Time Compute & System Reports:**
16. Snell et al. (2024) Test-Time Compute - https://arxiv.org/pdf/2408.03314.pdf
17. DeepSeek-V3 (2024) - https://arxiv.org/pdf/2412.19437.pdf
18. Qwen2.5 (2024) - https://arxiv.org/pdf/2412.15115.pdf
19. o1 System Card (2024) - https://arxiv.org/pdf/2412.16720.pdf
20. o3 Competitive Programming (2025) - https://arxiv.org/pdf/2502.06807.pdf
21. Kumar et al. (2025) Post-Training Survey - https://arxiv.org/pdf/2502.21321.pdf

---

## **Summary:**

**Main Body Papers:** ~55 foundational papers
**Appendix A (Emerging):** ~9 research papers
**Appendix B (Systems):** ~10 system reports

**Total:** ~74 papers (up from original ~47)

**New Additions:** 27 papers focused on:
- Reinforcement Learning foundations (7 papers)
- AI Feedback & Alignment (3 papers)
- Long-context innovations (2 papers)
- Modern architectures (5 papers)
- Test-time compute (1 paper)
- System reports & surveys (9 papers)
