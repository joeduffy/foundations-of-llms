Production systems integrate foundational techniques into deployable models, demonstrating how research advances translate into frontier capabilities. This appendix presents technical reports and system cards from leading organizations, documenting how combinations of pretraining, fine-tuning, reinforcement learning from feedback, and architectural innovations yield state-of-the-art performance.

These reports provide valuable case studies of technique integration, revealing engineering decisions, scaling strategies, and evaluation methodologies that inform both research and deployment practices. While not introducing novel algorithmic contributions, they demonstrate the practical application of foundational methods at unprecedented scale.

The progression from GPT-4 through reasoning-focused systems like o1 and o3 illustrates the evolution from pure language modeling toward systems that deliberately allocate inference-time computation for complex reasoning tasks. The DeepSeek and Qwen series demonstrate that strong performance can be achieved with open models through careful data curation and architectural optimization. The comprehensive post-training survey synthesizes recent advances in aligning language models through reinforcement learning and related techniques.

\textbf{Reports in this appendix:}
\begin{itemize}
    \item \textbf{OpenAI (2023)}: GPT-4 Technical Report---multimodal transformer achieving strong performance across diverse benchmarks.
    \item \textbf{Anthropic (2024)}: Claude 3 Model Family---Constitutional AI applied to production systems at scale.
    \item \textbf{DeepMind (2024)}: Gemini 1.5---multimodal model with extended context capability exceeding 1 million tokens.
    \item \textbf{Qwen Team (2024)}: Qwen2.5---open multilingual model series with extensive post-training optimization.
    \item \textbf{DeepSeek-AI (2024)}: DeepSeek-V3---671B mixture-of-experts with auxiliary-loss-free routing and Multi-Head Latent Attention.
    \item \textbf{OpenAI (2024)}: o1 System Card---reinforcement learning for extended chain-of-thought reasoning.
    \item \textbf{OpenAI (2025)}: o3 Competitive Programming---test-time compute scaling for complex reasoning tasks.
    \item \textbf{Kumar et al. (2025)}: LLM Post-Training Survey---comprehensive review of fine-tuning, reinforcement learning, and alignment techniques.
\end{itemize}
