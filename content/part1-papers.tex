% Part I Papers: Neural Beginnings & Learning Mechanisms (1943â€“1990)

\chapter{McCulloch \& Pitts (1943)}
\section*{A Logical Calculus of the Ideas Immanent in Nervous Activity}

This foundational paper established the mathematical basis for artificial neural networks by demonstrating that networks of simple threshold units could perform arbitrary logical computations.

\includepdf[pages=-,pagecommand={}]{pdfs/mcculloch-pitts-1943.pdf}

\chapter{Rosenblatt (1958)}
\section*{The Perceptron}

Rosenblatt introduced the first systematic learning algorithm for neural networks, demonstrating how machines could learn to classify patterns from training examples.

\includepdf[pages=-,pagecommand={}]{pdfs/rosenblatt-1958.pdf}

\chapter{Hopfield (1982)}
\section*{Neural Networks and Physical Systems with Emergent Collective Computational Abilities}

Hopfield networks introduced associative memory and energy-based models, showing how neural systems could store and retrieve patterns through collective dynamics.

\includepdf[pages=-,pagecommand={}]{pdfs/hopfield-1982.pdf}

\chapter{Rumelhart, Hinton \& Williams (1986)}
\section*{Learning Representations by Back-Propagating Errors}

The backpropagation algorithm solved the credit assignment problem in multilayer networks, enabling the training of deep architectures essential for modern language models.

\includepdf[pages=-,pagecommand={}]{pdfs/rumelhart-hinton-williams-1986.pdf}