This appendix captures the most significant recent developments in large language model research from 2023-2025, focusing on breakthroughs in safety, alignment, interpretability, efficiency, and reasoning capabilities. These papers represent the cutting edge of the field and point toward future directions in capability and safety development.

The papers in this section address fundamental challenges in deploying language models safely and effectively: alignment with human values, interpretability of internal representations, computational efficiency at scale, and systematic reasoning capabilities. Together, they demonstrate continued rapid progress in making language models more capable, efficient, and aligned with human values.

\section*{Key Advances}

\textbf{Safety and Alignment:} Advanced techniques for safe reinforcement learning from human feedback, constitutional AI methods, and comprehensive frameworks for AI evaluation and red teaming.

\textbf{Interpretability:} Breakthrough methods for understanding model internals through sparse autoencoders that reveal highly interpretable features within language models.

\textbf{Efficient Architectures:} Revolutionary state-space models like Mamba that achieve linear-time sequence modeling, and improved mixture-of-experts scaling laws.

\textbf{Enhanced Reasoning:} Advanced reasoning capabilities demonstrated by systems like OpenAI o1, showing significant improvements in mathematical and scientific problem-solving.

\section*{Papers in This Section}

\begin{enumerate}
\item \textbf{\hyperref[paper:bai-2023]{[2023] Safe RLHF: Safe Reinforcement Learning from Human Feedback (Bai et al.)}} -- Advanced techniques for safe reinforcement learning from human feedback.

\item \textbf{\hyperref[paper:cunningham-2023]{[2023] Sparse Autoencoders Find Highly Interpretable Features in Language Models (Cunningham et al.)}} -- Breakthrough methods for understanding model internals through sparse autoencoders.

\item \textbf{\hyperref[paper:casper-2024]{[2024] A Safe Harbor for AI Evaluation and Red Teaming (Casper et al.)}} -- Comprehensive frameworks for AI evaluation and red teaming.

\item \textbf{\hyperref[paper:openai-o1-2024]{[2024] OpenAI o1 System Card (OpenAI)}} -- Advanced reasoning capabilities demonstrated by systems like OpenAI o1.

\item \textbf{\hyperref[paper:gu-dao-2023]{[2023] Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Gu \& Dao)}} -- Revolutionary state-space models that achieve linear-time sequence modeling.

\item \textbf{\hyperref[paper:frantar-2024]{[2024] Scaling Laws for Fine-Grained Mixture of Experts (Frantar et al.)}} -- Improved mixture-of-experts scaling laws for efficient large models.

\item \textbf{\hyperref[paper:liu-2019-roberta]{[2019] RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al.)}} -- Optimized BERT pretraining approach with improved training procedures.
\end{enumerate}

% Papers follow directly after the introduction

\phantomsection
\label{paper:bai-2023}
\addcontentsline{toc}{subsection}{[2023] Safe RLHF: Safe Reinforcement Learning from Human Feedback (Bai et al.)}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/bai-2023.pdf}

\phantomsection
\label{paper:cunningham-2023}
\addcontentsline{toc}{subsection}{[2023] Sparse Autoencoders Find Highly Interpretable Features in Language Models (Cunningham et al.)}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/cunningham-2023.pdf}

\phantomsection
\label{paper:casper-2024}
\addcontentsline{toc}{subsection}{[2024] A Safe Harbor for AI Evaluation and Red Teaming (Casper et al.)}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/casper-2024.pdf}

\phantomsection
\label{paper:openai-o1-2024}
\addcontentsline{toc}{subsection}{[2024] OpenAI o1 System Card (OpenAI)}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/openai-2024-o1.pdf}

\phantomsection
\label{paper:gu-dao-2023}
\addcontentsline{toc}{subsection}{[2023] Mamba: Linear-Time Sequence Modeling with Selective State Spaces (Gu \& Dao)}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/gu-2023.pdf}

\phantomsection
\label{paper:frantar-2024}
\addcontentsline{toc}{subsection}{[2024] Scaling Laws for Fine-Grained Mixture of Experts (Frantar et al.)}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/frantar-2024.pdf}

\phantomsection
\label{paper:liu-2019-roberta}
\addcontentsline{toc}{subsection}{[2019] RoBERTa: A Robustly Optimized BERT Pretraining Approach (Liu et al.)}
% PDF to be added: https://arxiv.org/pdf/1907.11692.pdf