% Part VII Papers: Open LLMs and Modern Frontier (2023â€“2024)

\addcontentsline{toc}{subsection}{[2023] LLaMA: Open and Efficient Foundation Language Models (Touvron et al.)}
\phantomsection
\label{paper:touvron-2023-llama}
\input{content/summary-touvron-2023-llama}
\includepdf[pages=-,pagecommand={}]{pdfs/touvron-2023.pdf}

\addcontentsline{toc}{subsection}{[2023] Llama 2: Open Foundation and Fine-Tuned Chat Models (Touvron et al.)}
\phantomsection
\label{paper:touvron-2023-llama2}
\input{content/summary-touvron-2023-llama2}
\includepdf[pages=-,pagecommand={}]{pdfs/touvron-2023-llama2.pdf}

\addcontentsline{toc}{subsection}{[2023] Code Llama: Open Foundation Models for Code (Rozi\`{e}re et al.)}
\phantomsection
\label{paper:roziere-2023}
\input{content/summary-roziere-2023}
\includepdf[pages=-,pagecommand={}]{pdfs/roziere-2023.pdf}

\addcontentsline{toc}{subsection}{[2023] Direct Preference Optimization (Rafailov et al.)}
\phantomsection
\label{paper:rafailov-2023-dpo}
\input{content/summary-rafailov-2023-dpo}
\includepdf[pages=-,pagecommand={}]{pdfs/rafailov-2023-dpo.pdf}

\addcontentsline{toc}{subsection}{[2023] RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback (Lee et al.)}
\phantomsection
\label{paper:lee-2023-rlaif}
\input{content/summary-lee-2023-rlaif}
\includepdf[pages=-,pagecommand={}]{pdfs/lee-2023-rlaif.pdf}

\addcontentsline{toc}{subsection}{[2023] Ring Attention with Blockwise Transformers for Near-Infinite Context (Liu et al.)}
\phantomsection
\label{paper:liu-2023-ring-attention}
\input{content/summary-liu-2023-ring-attention}
\includepdf[pages=-,pagecommand={}]{pdfs/liu-2023-ring-attention.pdf}

\addcontentsline{toc}{subsection}{[2023] QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers et al.)}
\phantomsection
\label{paper:dettmers-2023-qlora}
\input{content/summary-dettmers-2023-qlora}
\includepdf[pages=-,pagecommand={}]{pdfs/dettmers-2023.pdf}

\addcontentsline{toc}{subsection}{[2023] GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints (Ainslie et al.)}
\phantomsection
\label{paper:ainslie-2023-gqa}
\input{content/summary-ainslie-2023-gqa}
\includepdf[pages=-,pagecommand={}]{pdfs/ainslie-2023-gqa.pdf}

\addcontentsline{toc}{subsection}{[2024] Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention (Munkhdalai et al.)}
\phantomsection
\label{paper:munkhdalai-2024-infini}
\input{content/summary-munkhdalai-2024-infini}
\includepdf[pages=-,pagecommand={}]{pdfs/munkhdalai-2024-infini-attention.pdf}

\addcontentsline{toc}{subsection}{[2024] Self-Rewarding Language Models (Yuan et al.)}
\phantomsection
\label{paper:yuan-2024-self-rewarding}
\input{content/summary-yuan-2024-self-rewarding}
\includepdf[pages=-,pagecommand={}]{pdfs/yuan-2024-self-rewarding.pdf}

\addcontentsline{toc}{subsection}{[2024] DeepSeekMath: Pushing the Limits of Mathematical Reasoning (Shao et al.)}
\phantomsection
\label{paper:shao-2024-deepseekmath}
\input{content/summary-shao-2024-deepseekmath}
\includepdf[pages=-,pagecommand={}]{pdfs/shao-2024-deepseekmath.pdf}

\addcontentsline{toc}{subsection}{[2024] DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model (Zhu et al.)}
\phantomsection
\label{paper:zhu-2024-deepseek-v2}
\input{content/summary-zhu-2024-deepseek-v2}
\includepdf[pages=-,pagecommand={}]{pdfs/zhu-2024-deepseek-v2.pdf}

\addcontentsline{toc}{subsection}{[2024] Mixtral of Experts (Jiang et al.)}
\phantomsection
\label{paper:jiang-2024-mixtral}
\input{content/summary-jiang-2024-mixtral}
\includepdf[pages=-,pagecommand={}]{pdfs/mistral-2024.pdf}

\addcontentsline{toc}{subsection}{[2024] The Llama 3 Herd of Models (Dubey et al.)}
\phantomsection
\label{paper:touvron-2024-llama3}
\input{content/summary-touvron-2024-llama3}
\includepdf[pages=-,pagecommand={}]{pdfs/touvron-2024-llama3.pdf}

\addcontentsline{toc}{subsection}{[2024] Scaling LLM Test-Time Compute Optimally (Snell et al.)}
\phantomsection
\label{paper:snell-2024-test-time}
\input{content/summary-snell-2024-test-time}
\includepdf[pages=-,pagecommand={}]{pdfs/snell-2024-test-time-compute.pdf}
