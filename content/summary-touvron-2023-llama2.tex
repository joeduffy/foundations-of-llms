% Paper Summary: Llama 2: Open Foundation and Fine-Tuned Chat Models (Touvron et al., 2023)

\begin{papersummary}{2023}{Llama 2: Open Foundation and Fine-Tuned Chat Models}{Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, et al.}{Llama 2 released open-weight models up to 70B parameters with commercial licensing, establishing the foundation for the open-source LLM ecosystem.}

\summaryheading{Key Ideas}
Llama 2 introduced pretrained models at 7B, 13B, and 70B parameters, trained on 2 trillion tokens---40\% more than LLaMA 1. Key architectural improvements included Grouped-Query Attention (GQA) for efficient inference and extended context length to 4096 tokens. The paper also released Llama 2-Chat models fine-tuned for dialogue using RLHF with over 1 million human annotations. Detailed safety evaluations and red-teaming results demonstrated responsible development practices. The permissive license enabled commercial use, democratizing access to high-quality LLMs.

\summaryheading{Follow-on Works}
Llama 2 spawned an extensive ecosystem of fine-tuned variants: Code Llama (Rozi\`{e}re et al., 2023) for programming, Vicuna, WizardLM, and countless community adaptations. The model enabled academic research on LLM capabilities and alignment. Llama 3 (Dubey et al., 2024) built on these foundations. QLoRA (\hyperref[paper:dettmers-2023-qlora]{Dettmers et al., 2023}) made Llama 2 fine-tuning accessible on consumer hardware.

\summaryheading{Lasting Contributions}
Llama 2 democratized access to competitive large language models, catalyzing the open-source LLM movement. The combination of strong performance, permissive licensing, and detailed technical documentation made it the foundation for thousands of derivative models and research projects. Llama 2's adoption of GQA standardized this technique across the industry. The detailed RLHF methodology and safety evaluation framework influenced how subsequent open models approach alignment. Llama 2 demonstrated that open development could produce models competitive with proprietary systems, fundamentally changing the LLM landscape.

\end{papersummary}
