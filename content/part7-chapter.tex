The years 2023-2024 witnessed the democratization of large language models through open-source releases and continued advances at the frontier. This period established that competitive language models could be developed outside major labs, while frontier models pushed boundaries in multimodality, efficiency, and capability.

The release of LLaMA catalyzed an explosion of open research and applications, while techniques like QLoRA made fine-tuning accessible to individual researchers. Meanwhile, GPT-4, Mixtral, and Gemini demonstrated new architectures and capabilities at the frontier.

\section*{Key Advances}

\textbf{Open Foundation Models (2023):} LLaMA proved that smaller, well-trained models could match larger models' performance, spurring thousands of derivative works and applications.

\textbf{Efficient Fine-tuning (2023):} QLoRA combined quantization with LoRA, enabling fine-tuning of 65B parameter models on single GPUs, democratizing model customization.

\textbf{Multimodal Reasoning (2023):} GPT-4 demonstrated strong performance across text, vision, and reasoning tasks, establishing new benchmarks for capability and safety.

\textbf{Sparse Mixture of Experts (2024):} Mixtral showed that sparse MoE architectures could deliver frontier performance with better inference efficiency than dense models.

\textbf{Long Context and Efficiency (2024):} Gemini 1.5 achieved million-token context windows while maintaining strong performance, opening new applications in document understanding and reasoning.

\section*{Papers in This Section}

\begin{enumerate}
\item \textbf{\hyperref[paper:touvron-2023]{[2023] LLaMA: Open and Efficient Foundation Language Models (Touvron et al.)}} -- Released LLaMA, demonstrating that open models could achieve GPT-3 level performance.

\item \textbf{\hyperref[paper:dettmers-2023]{[2023] QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers et al.)}} -- Introduced QLoRA, making large model fine-tuning accessible through 4-bit quantization.

\item \textbf{\hyperref[paper:openai-2023]{[2023] GPT-4 Technical Report (OpenAI)}} -- Released GPT-4, setting new standards for capability, safety, and multimodal understanding.

\item \textbf{\hyperref[paper:mistral-2024]{[2024] Mixtral of Experts (Jiang et al.)}} -- Developed Mixtral, showing sparse MoE could deliver frontier performance efficiently.

\item \textbf{\hyperref[paper:deepmind-2024]{[2024] Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context (Team et al.)}} -- Created Gemini 1.5 with million-token contexts and strong multimodal capabilities.
\end{enumerate}

\newpage

% Papers follow directly after the introduction

\addcontentsline{toc}{subsection}{[2023] LLaMA: Open and Efficient Foundation Language Models (Touvron et al.)}
\phantomsection
\label{paper:touvron-2023}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/touvron-2023.pdf}

\addcontentsline{toc}{subsection}{[2023] QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers et al.)}
\phantomsection
\label{paper:dettmers-2023}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/dettmers-2023.pdf}

\addcontentsline{toc}{subsection}{[2023] GPT-4 Technical Report (OpenAI)}
\phantomsection
\label{paper:openai-2023}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/openai-2023.pdf}

\addcontentsline{toc}{subsection}{[2024] Mixtral of Experts (Jiang et al.)}
\phantomsection
\label{paper:mistral-2024}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/mistral-2024.pdf}

\addcontentsline{toc}{subsection}{[2024] Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context (Team et al.)}
\phantomsection
\label{paper:deepmind-2024}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/deepmind-2024.pdf}