\section*{Introduction to Appendix B}

This appendix covers foundational papers for AI agents—systems that use large language models to reason, plan, and act autonomously in complex environments. These papers establish core techniques for building agents that use tools, engage in multi-step reasoning, and execute long-horizon plans.

\subsection*{Key Advances}

\textbf{Code as Action (2022-2024):} Code as Policies pioneered using language models to generate executable code for robotic control, bridging natural language and precise executable commands. CodeAct demonstrated that executable code actions significantly outperform text-only approaches for agent tasks.

\textbf{Tool Use (2023):} Toolformer showed how language models can learn to use external tools—calculators, search engines, databases—through self-supervised learning without massive tool-specific training data.

\textbf{Deliberate Reasoning (2023):} Tree of Thoughts generalized chain-of-thought reasoning to enable systematic exploration of intermediate reasoning steps, dramatically improving performance on complex problem-solving tasks.

\textbf{Learning from Failure (2023):} Reflexion introduced verbal reinforcement learning, where agents learn from failures by reflecting on mistakes and storing insights in memory for future tasks.

\textbf{Agent Architecture (2025):} Recent work on foundation agents and planning abstractions synthesizes these advances into comprehensive frameworks for autonomous operation.
