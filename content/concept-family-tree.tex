% Concept Family Tree: The Lineage of Large Language Models
% A visual representation of how core concepts evolved and interconnected

\begin{figure}[p]
\centering
\begin{tikzpicture}[
    % Node styles
    era/.style={
        font=\footnotesize\bfseries,
        text=black!60,
        anchor=west
    },
    concept/.style={
        draw=black!70,
        fill=white,
        rounded corners=2pt,
        minimum height=1.6em,
        minimum width=2cm,
        font=\scriptsize,
        align=center,
        inner sep=3pt
    },
    foundational/.style={
        concept,
        fill=black!8,
        line width=0.8pt
    },
    architectural/.style={
        concept,
        fill=black!3
    },
    technique/.style={
        concept,
        fill=white,
        dashed
    },
    milestone/.style={
        concept,
        fill=black!15,
        line width=1pt,
        font=\scriptsize\bfseries
    },
    % Edge styles
    evolves/.style={
        ->,
        >=Stealth,
        line width=0.5pt,
        black!60
    },
    enables/.style={
        ->,
        >=Stealth,
        line width=0.4pt,
        black!40,
        dashed
    },
    combines/.style={
        ->,
        >=Stealth,
        line width=0.6pt,
        black!50,
        densely dotted
    }
]

% Era labels (left side) with years below
\node[era, align=center] at (-6.2, 0) {Part 1\\[-0.3em]{\tiny\mdseries 1943--90}};
\node[era, align=center] at (-6.2, -2.5) {Part 2\\[-0.3em]{\tiny\mdseries 1990--2013}};
\node[era, align=center] at (-6.2, -5) {Part 3\\[-0.3em]{\tiny\mdseries 2012--15}};
\node[era, align=center] at (-6.2, -7.5) {Part 4\\[-0.3em]{\tiny\mdseries 2017--19}};
\node[era, align=center] at (-6.2, -10) {Part 5\\[-0.3em]{\tiny\mdseries 2019--20}};
\node[era, align=center] at (-6.2, -12.5) {Part 6\\[-0.3em]{\tiny\mdseries 2021--22}};
\node[era, align=center] at (-6.2, -15) {Part 7\\[-0.3em]{\tiny\mdseries 2023--24}};

% Horizontal era separators
\foreach \y in {-1.25, -3.75, -6.25, -8.75, -11.25, -13.75} {
    \draw[black!15, line width=0.3pt] (-5, \y) -- (6.5, \y);
}

% ============================================
% PART I: Neural Beginnings (1943-1990)
% ============================================

\node[foundational] (neuron) at (-3, 0.3) {Artificial\\Neuron};
\node[foundational] (perceptron) at (-0.5, 0.3) {Perceptron\\Learning};
\node[foundational] (hopfield) at (-3, -0.6) {Associative\\Memory};
\node[foundational] (backprop) at (2, 0) {Backpropagation};
\node[architectural] (rnn) at (4.5, 0) {Recurrent\\Networks};

\draw[evolves] (neuron) -- (perceptron);
\draw[evolves] (perceptron) -- (backprop);
\draw[enables] (hopfield) -- (backprop);
\draw[evolves] (backprop) -- (rnn);

% ============================================
% PART II: Sequence Models (1990-2013)
% ============================================

\node[foundational] (lstm) at (-3, -2.2) {LSTM\\Gating};
\node[architectural] (nplm) at (-0.5, -2.5) {Neural\\Language Model};
\node[foundational] (embeddings) at (2, -2.2) {Word\\Embeddings};
\node[architectural] (seqgen) at (4.5, -2.8) {Sequence\\Generation};
\node[technique] (varinf) at (2, -3.1) {Variational\\Inference};

\draw[evolves] (rnn) -- (lstm);
\draw[evolves] (lstm) -- (nplm);
\draw[evolves] (nplm) -- (embeddings);
\draw[evolves] (lstm) -- (seqgen);
\draw[enables] (backprop) to[bend right=15] (nplm);

% ============================================
% PART III: Deep Learning & Attention (2012-2015)
% ============================================

\node[milestone] (deeplearning) at (-3, -4.7) {Deep Learning\\Revolution};
\node[technique] (dropout) at (-3, -5.6) {Dropout};
\node[technique] (batchnorm) at (-0.5, -5.6) {Batch\\Normalization};
\node[foundational] (resnet) at (-0.5, -4.7) {Residual\\Connections};
\node[architectural] (seq2seq) at (2, -4.7) {Sequence-to-\\Sequence};
\node[foundational] (attention) at (4.5, -4.7) {Attention\\Mechanism};
\node[technique] (bpe) at (4.5, -5.6) {Subword\\Tokenization};
\node[technique] (adam) at (2, -5.6) {Adaptive\\Optimization};

\draw[evolves] (backprop) to[bend left=20] (deeplearning);
\draw[evolves] (deeplearning) -- (resnet);
\draw[enables] (dropout) -- (deeplearning);
\draw[enables] (batchnorm) -- (resnet);
\draw[evolves] (lstm) to[bend right=10] (seq2seq);
\draw[evolves] (seq2seq) -- (attention);
\draw[enables] (embeddings) -- (seq2seq);

% ============================================
% PART IV: Transformer Era (2017-2019)
% ============================================

\node[milestone] (transformer) at (0.75, -7.2) {Transformer};
\node[technique] (layernorm) at (-3, -7.5) {Layer\\Normalization};
\node[technique] (moe) at (-3, -8.3) {Mixture of\\Experts};
\node[foundational] (pretrain) at (3.5, -7.2) {Self-Supervised\\Pretraining};
\node[architectural] (bert) at (2, -8.1) {Bidirectional\\(BERT)};
\node[architectural] (gpt) at (5, -8.1) {Autoregressive\\(GPT)};
\node[technique] (rlhf) at (-0.5, -8.4) {RLHF};
\node[technique] (ppo) at (-1.6, -8.4) {PPO};

\draw[evolves] (attention) -- (transformer);
\draw[evolves] (resnet) to[bend right=10] (transformer);
\draw[enables] (layernorm) -- (transformer);
\draw[evolves] (transformer) -- (pretrain);
\draw[evolves] (pretrain) -- (bert);
\draw[evolves] (pretrain) -- (gpt);
\draw[enables] (bpe) to[bend left=15] (transformer);
\draw[enables] (ppo) -- (rlhf);

% ============================================
% PART V: Emergence and Scale (2019-2020)
% ============================================

\node[milestone] (scaling) at (-2, -9.7) {Scaling\\Laws};
\node[foundational] (emergence) at (0.75, -9.7) {Emergent\\Capabilities};
\node[architectural] (fewshot) at (3.5, -9.7) {In-Context\\Learning};
\node[architectural] (rag) at (5.5, -9.7) {Retrieval\\Augmentation};
\node[technique] (mqa) at (-2, -10.6) {Multi-Query\\Attention};

\draw[evolves] (gpt) -- (scaling);
\draw[evolves] (scaling) -- (emergence);
\draw[evolves] (emergence) -- (fewshot);
\draw[enables] (pretrain) to[bend left=10] (rag);
\draw[enables] (moe) to[bend right=15] (scaling);

% ============================================
% PART VI: Efficiency, Alignment, Reasoning (2021-2022)
% ============================================

\node[technique] (lora) at (-3.5, -12.2) {LoRA};
\node[technique] (rope) at (-2, -12.2) {Rotary\\Embeddings};
\node[technique] (flash) at (-0.5, -12.2) {Flash\\Attention};
\node[milestone] (instruct) at (1.5, -12.2) {Instruction\\Following};
\node[foundational] (cot) at (3.5, -12.2) {Chain-of-\\Thought};
\node[architectural] (constitutional) at (5.5, -12.2) {Constitutional\\AI};
\node[technique] (chinchilla) at (-3.5, -13) {Compute-\\Optimal};
\node[architectural] (react) at (3.5, -13) {Tool Use\\(ReAct)};

\draw[evolves] (rlhf) to[bend right=15] (instruct);
\draw[evolves] (fewshot) -- (cot);
\draw[evolves] (instruct) -- (constitutional);
\draw[evolves] (cot) -- (react);
\draw[enables] (scaling) to[bend right=10] (chinchilla);
\draw[enables] (mqa) -- (flash);

% ============================================
% PART VII: Open LLMs and Modern Frontier (2023-2024)
% ============================================

\node[milestone] (openmodels) at (-3, -14.7) {Open\\Models};
\node[technique] (dpo) at (-1, -14.7) {Direct\\Preference};
\node[technique] (qlora) at (-3, -15.5) {QLoRA};
\node[technique] (gqa) at (-1, -15.5) {Grouped-Query\\Attention};
\node[architectural] (moescale) at (1.5, -14.7) {Sparse\\MoE};
\node[foundational] (testtime) at (4, -14.7) {Test-Time\\Compute};
\node[architectural] (selfreward) at (4, -15.5) {Self-\\Rewarding};

\draw[evolves] (instruct) to[bend right=5] (openmodels);
\draw[evolves] (constitutional) -- (dpo);
\draw[evolves] (lora) -- (qlora);
\draw[evolves] (mqa) to[bend right=10] (gqa);
\draw[evolves] (moe) to[bend right=20] (moescale);
\draw[evolves] (cot) to[bend left=10] (testtime);
\draw[enables] (dpo) -- (selfreward);

% ============================================
% Legend
% ============================================

\begin{scope}[shift={(7.5, -7.5)}]
    \node[font=\scriptsize\bfseries, anchor=north west] at (0, 0.3) {Legend};

    \node[foundational, minimum width=1.2cm] (leg1) at (0.6, -0.4) {};
    \node[font=\tiny, anchor=west] at (1.4, -0.4) {Foundational};

    \node[milestone, minimum width=1.2cm] (leg2) at (0.6, -0.9) {};
    \node[font=\tiny, anchor=west] at (1.4, -0.9) {Milestone};

    \node[architectural, minimum width=1.2cm] (leg3) at (0.6, -1.4) {};
    \node[font=\tiny, anchor=west] at (1.4, -1.4) {Architecture};

    \node[technique, minimum width=1.2cm] (leg4) at (0.6, -1.9) {};
    \node[font=\tiny, anchor=west] at (1.4, -1.9) {Technique};

    \draw[evolves] (0.1, -2.5) -- (1.1, -2.5);
    \node[font=\tiny, anchor=west] at (1.4, -2.5) {Evolves into};

    \draw[enables] (0.1, -3) -- (1.1, -3);
    \node[font=\tiny, anchor=west] at (1.4, -3) {Enables};
\end{scope}

\end{tikzpicture}

\caption{Genealogy of core concepts in large language model development. Foundational contributions (dark fill) establish theoretical frameworks; milestones (bold border) mark paradigm shifts; architectural innovations (light fill) introduce structural patterns; techniques (dashed) provide enabling methods. Solid arrows indicate direct conceptual evolution; dashed arrows show enabling relationships.}
\label{fig:concept-family-tree}
\end{figure}
