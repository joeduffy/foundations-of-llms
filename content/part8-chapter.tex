The years 2023-2024 witnessed the democratization of large language models through open-source releases and continued advances at the frontier. This period established that competitive language models could be developed outside major labs, while frontier models pushed boundaries in multimodality, efficiency, and capability.

The democratization began with \hyperref[paper:touvron-2023]{LLaMA (Touvron et al., 2023)}, which proved that smaller, well-trained models could match larger models' performance. LLaMA's open release catalyzed an explosion of research and applications, spurring thousands of derivative works and establishing that frontier capabilities were not limited to major labs.

Accessibility was further enhanced by \hyperref[paper:dettmers-2023]{QLoRA (Dettmers et al., 2023)}, which combined quantization with LoRA to enable fine-tuning of 65B parameter models on single GPUs. This breakthrough democratized model customization, allowing individual researchers and smaller organizations to adapt large models for specific applications.

At the frontier, \hyperref[paper:openai-2023]{GPT-4 (OpenAI, 2023)} demonstrated strong performance across text, vision, and reasoning tasks, establishing new benchmarks for capability and safety. GPT-4's multimodal capabilities marked a significant expansion beyond text-only processing, handling complex visual and textual reasoning tasks.

Efficiency advances continued with \hyperref[paper:mistral-2024]{Mixtral (Jiang et al., 2024)}, which showed that sparse mixture-of-experts architectures could deliver frontier performance with better inference efficiency than dense models. Finally, \hyperref[paper:deepmind-2024]{Gemini 1.5 (Team et al., 2024)} achieved million-token context windows while maintaining strong performance, opening new applications in document understanding and long-form reasoning that were previously impossible.

\newpage

% Papers follow directly after the introduction

\addcontentsline{toc}{subsection}{[2023] LLaMA: Open and Efficient Foundation Language Models (Touvron et al.)}
\phantomsection
\label{paper:touvron-2023}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/touvron-2023.pdf}

\addcontentsline{toc}{subsection}{[2023] QLoRA: Efficient Finetuning of Quantized LLMs (Dettmers et al.)}
\phantomsection
\label{paper:dettmers-2023}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/dettmers-2023.pdf}

\addcontentsline{toc}{subsection}{[2023] GPT-4 Technical Report (OpenAI)}
\phantomsection
\label{paper:openai-2023}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/openai-2023.pdf}

\addcontentsline{toc}{subsection}{[2024] Mixtral of Experts (Jiang et al.)}
\phantomsection
\label{paper:mistral-2024}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/mistral-2024.pdf}

\addcontentsline{toc}{subsection}{[2024] Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context (Team et al.)}
\phantomsection
\label{paper:deepmind-2024}
\includepdf[pages=-,pagecommand={\thispagestyle{empty}}]{pdfs/deepmind-2024.pdf}